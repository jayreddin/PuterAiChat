{"chunk":10,"numChunks":47,"fileHash":"DS6QWbTdrmdJEfNC8Ec7aEISJw5n4IF3kMzfDlJvsks=","filePath":"attached_assets/Puterexamples.md","content":"            const outputDiv \\= document.getElementById('output');  \n              \n            // DeepSeek Chat with streaming  \n            outputDiv.innerHTML \\+= '\\<h2\\>DeepSeek Chat Response:\\</h2\\>';  \n            const chatResponse \\= await puter.ai.chat(  \n                \"Explain the significance of dark matter in the universe\",   \n                {  \n                    model: 'deepseek-chat',  \n                    stream: true  \n                }  \n            );  \n              \n            for await (const part of chatResponse) {  \n                if (part?.text) {  \n                    outputDiv.innerHTML \\+= part.text;  \n                }  \n            }  \n              \n            // DeepSeek Reasoner with streaming  \n            outputDiv.innerHTML \\+= '\\<h2\\>DeepSeek Reasoner Response:\\</h2\\>';  \n            const reasonerResponse \\= await puter.ai.chat(  \n                \"Explain the significance of dark matter in the universe\",   \n                {  \n                    model: 'deepseek-reasoner',  \n                    stream: true  \n                }  \n            );  \n              \n            for await (const part of reasonerResponse) {  \n                if (part?.text) {  \n                    outputDiv.innerHTML \\+= part.text;  \n                }  \n            }  \n        }\n\n        streamResponse();  \n    \\</script\\>  \n\\</body\\>  \n\\</html\\>\n\n## **Example 4**\n\n## Comparing Models\n\nHere's how to compare responses from both DeepSeek models:\n\n\\<html\\>  \n\\<body\\>  \n    \\<script src=\"https://js.puter.com/v2/\"\\>\\</script\\>  \n    \\<script\\>  \n    (async () \\=\\> {  \n        // DeepSeek Chat  \n        const chat\\_resp \\= await puter.ai.chat(  \n"}